from __future__ import annotations

import json
import time
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple
from pathlib import Path

from openai import OpenAI

# ----------------------------
# Konfiguracja klienta
# ----------------------------
client = OpenAI(
    base_url="http://192.168.100.65:8080",
    api_key="ollama",
)

MODEL = "gpt-oss:120b"


# ----------------------------
# Klasa pamiÄ™ci rozmowy
# ----------------------------
@dataclass
class ChatMemory:
    system_prompt: str
    items: List[Dict[str, Any]] = field(default_factory=list)
    summary: Optional[str] = None
    history_file: Optional[Path] = None  # plik do zapisu/Å‚adowania

    def __post_init__(self) -> None:
        # 1ï¸âƒ£ Dodajemy systemowy prompt
        self.items.append(
            {
                "role": "system",
                "content": [{"type": "text", "text": self.system_prompt}],
            }
        )

        # 2ï¸âƒ£ Åadujemy istniejÄ…cÄ… historiÄ™ (jeÅ›li plik istnieje)
        if self.history_file and self.history_file.exists():
            self._load_from_file()

    # -------------------------------------------------
    # Metody dodajÄ…ce wiadomoÅ›ci
    # -------------------------------------------------
    def add_user(self, text: str) -> None:
        self.items.append(
            {
                "role": "user",
                "content": [{"type": "text", "text": text}],
            }
        )
        self._save_to_file()

    def add_assistant(self, text: str) -> None:
        self.items.append(
            {
                "role": "assistant",
                "content": [{"type": "text", "text": text}],
            }
        )
        self._save_to_file()

    def add_tool_result(self, tool_name: str, result: Dict[str, Any]) -> None:
        """Dodaje wynik wywoÅ‚ania narzÄ™dzia do historii"""
        self.items.append(
            {
                "role": "tool",
                "content": [
                    {
                        "type": "text",
                        "text": f" Wynik narzÄ™dzia **{tool_name}**:\n{json.dumps(result, ensure_ascii=False, indent=2)}",
                    }
                ],
            }
        )
        self._save_to_file()

    # -------------------------------------------------
    # Budowanie wejÅ›cia dla API
    # -------------------------------------------------
    def build_input(self) -> List[Dict[str, Any]]:
        """Zwraca listÄ™ wiadomoÅ›ci gotowÄ… do wysÅ‚ania do API.
        JeÅ›li istnieje streszczenie â€“ wstrzykuje je jako dodatkowy systemowy komunikat.
        """
        if self.summary:
            return [
                self.items[0],  # oryginalny system prompt
                {
                    "role": "system",
                    "content": [
                        {
                            "type": "text",
                            "text": f"ğŸ”” STRESZCZENIE DOTYCHCZASOWEJ ROZMOWY:\n{self.summary}",
                        }
                    ],
                },
                *self.items[1:],  # caÅ‚a historia (bez pierwszego systemowego)
            ]
        return self.items

    # -------------------------------------------------
    # ObsÅ‚uga dÅ‚ugiej historii â€“ STRESZCZANIE
    # -------------------------------------------------
    def approx_char_count(self) -> int:
        total = 0
        for msg in self.items:
            for c in msg.get("content", []):
                if c.get("type") == "text":
                    total += len(c.get("text", ""))
        if self.summary:
            total += len(self.summary)
        return total

    def summarize_history(self, keep_last_n: int = 6) -> None:
        """Streszcza starszÄ… czÄ™Å›Ä‡ historii, zostawiajÄ…c ostatnie `keep_last_n` wiadomoÅ›ci."""
        if len(self.items) <= 1 + keep_last_n:
            return  # za krÃ³tko â€“ nie streszczamy

        # Wydzielamy czÄ™Å›Ä‡ do streszczenia (wszystko POZA ostatnimi `keep_last_n` wiadomoÅ›ciami)
        to_summarize = self.items[1:-keep_last_n]  # pomijamy systemowy prompt
        tail = self.items[-keep_last_n:]  # ostatnie wiadomoÅ›ci (zostajÄ… bez zmian)

        # Przygotowanie wejÅ›cia dla modeluâ€‘streszczaciela
        summarizer_input = [
            {
                "role": "system",
                "content": [
                    {
                        "type": "text",
                        "text": "JesteÅ› ekspertem od streszczania rozmÃ³w. StwÃ³rz KRÃ“TKIE podsumowanie (max 8 punktÃ³w) dotychczasowej rozmowy. Zachowaj kluczowe decyzje, preferencje uÅ¼ytkownika i waÅ¼ne dane. Pisz po polsku.",
                    }
                ],
            },
            {
                "role": "user",
                "content": [{"type": "text", "text": "StreÅ›Ä‡ poniÅ¼szÄ… historiÄ™:"}],
            },
            *to_summarize,
        ]

        print("\nğŸ”„ Streszczam historiÄ™â€¦\n")
        resp = client.responses.create(
            model=MODEL,
            input=summarizer_input,
            temperature=0.2,
        )
        self.summary = resp.output_text.strip()
        # ZastÄ™pujemy starÄ… historiÄ™ nowÄ… (system + ogon)
        self.items = [self.items[0]] + tail
        self._save_to_file()
        print(
            f"âœ… Historia zostaÅ‚a streszczona! (dÅ‚ugoÅ›Ä‡: {len(self.summary)} znakÃ³w)\n"
        )

    # -------------------------------------------------
    # Zapisywanie / Å‚adowanie historii do pliku JSON
    # -------------------------------------------------
    def _save_to_file(self) -> None:
        if not self.history_file:
            return
        data = {
            "system_prompt": self.system_prompt,
            "items": self.items,
            "summary": self.summary,
        }
        with open(self.history_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def _load_from_file(self) -> None:
        with open(self.history_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        self.system_prompt = data["system_prompt"]
        self.items = data["items"]
        self.summary = data.get("summary")


# ----------------------------
# NARZÄ˜DZIA (function calling)
# ----------------------------
def local_time_tool(_: Dict[str, Any]) -> Dict[str, Any]:
    """Zwraca aktualny czas (epoch + czytelny format)."""
    now = time.time()
    return {
        "epoch": now,
        "iso": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(now)),
    }


TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "local_time",
            "description": "Zwraca aktualny czas systemowy (godzina, data).",
            "parameters": {
                "type": "object",
                "properties": {},
                "additionalProperties": False,
            },
        },
    }
]

TOOL_DISPATCH = {"local_time": local_time_tool}


# ----------------------------
# GÅÃ“WNA LOGIKA CZATU
# ----------------------------
def run_with_tools(memory: ChatMemory, temperature: float = 0.7) -> str:
    """WysyÅ‚a historiÄ™ do modelu. ObsÅ‚uguje wywoÅ‚ania narzÄ™dzi."""
    # 1ï¸âƒ£ Pierwsze wywoÅ‚anie API
    resp = client.responses.create(
        model=MODEL,
        input=memory.build_input(),
        temperature=temperature,
        tools=TOOLS,  # usuÅ„ tÄ™ liniÄ™ jeÅ›li Twoje proxy nie obsÅ‚uguje tools
    )

    # Sprawdzamy, czy model prosi o wywoÅ‚anie narzÄ™dzia
    tool_calls = []
    for item in getattr(resp, "output", []):
        if isinstance(item, dict) and item.get("type") in (
            "tool_call",
            "function_call",
        ):
            tool_calls.append(item)

    if not tool_calls:
        return resp.output_text

    # 2ï¸âƒ£ Wykonujemy kaÅ¼de narzÄ™dzie i dodajemy wynik do historii
    for call in tool_calls:
        # Normalizacja nazwy i argumentÃ³w (rÃ³Å¼ne proxy mogÄ… to nazywaÄ‡ inaczej)
        name = call.get("function", {}).get("name") or call.get("name")
        arg_str = call.get("function", {}).get("arguments", "{}")
        try:
            args = json.loads(arg_str) if isinstance(arg_str, str) else arg_str
        except json.JSONDecodeError:
            args = {}

        if name not in TOOL_DISPATCH:
            result = {"error": f"Nieznane narzÄ™dzie: {name}"}
        else:
            result = TOOL_DISPATCH[name](args)

        memory.add_tool_result(name, result)

    # 3ï¸âƒ£ DociÄ…gniÄ™cie finalnej odpowiedzi (po wynikach narzÄ™dzi)
    resp2 = client.responses.create(
        model=MODEL,
        input=memory.build_input(),
        temperature=temperature,
        tools=TOOLS,
    )
    return resp2.output_text


# ----------------------------
# GÅÃ“WNA PÄ˜TLA CZATU
# ----------------------------
def main() -> None:
    # ÅšcieÅ¼ka do pliku z historiÄ… (moÅ¼esz zmieniÄ‡ nazwÄ™)
    HISTORY_FILE = Path("chat_history.json")

    memory = ChatMemory(
        system_prompt=(
            "JesteÅ› pomocnym asystentem. Odpowiadasz PO POLSKU. "
            "JesteÅ› uprzejmy, zwiÄ™zÅ‚y i precyzyjny. "
            "Gdy potrzebujesz danych â€“ dopytujesz, ale nie naduÅ¼ywasz pytaÅ„."
        ),
        history_file=HISTORY_FILE,
    )

    # ===================================================================
    #  ğŸ”¥ğŸ”¥ğŸ”¥  POCZÄ„TKOWA HISTORIA (juÅ¼ wczytana przy starcie!)  ğŸ”¥ğŸ”¥ğŸ”¥
    # ===================================================================
    # JeÅ›li plik nie istniaÅ‚ â€“ dodajemy przykÅ‚adowÄ… rozmowÄ™.
    # JeÅ›li plik istnieje â€“ historia zostanie wczytana automatycznie.
    if not HISTORY_FILE.exists():
        print("ğŸ‘‹ TworzÄ™ przykÅ‚adowÄ… historiÄ™ startowÄ…â€¦\n")

        # 1ï¸âƒ£ UÅ¼ytkownik
        memory.add_user("CzeÅ›Ä‡! Jak mogÄ™ dzisiaj Ci pomÃ³c?")
        # 2ï¸âƒ£ Asystent
        memory.add_assistant(
            "CzeÅ›Ä‡! MogÄ™ odpowiadaÄ‡ na pytania, podawaÄ‡ informacje, pomagaÄ‡ z kodem lub planowaniem. Co CiÄ™ dzisiaj interesuje?"
        )
        # 3ï¸âƒ£ UÅ¼ytkownik
        memory.add_user(
            "PotrzebujÄ™ prostego skryptu Python, ktÃ³ry czyta plik CSV i liczy wiersze."
        )
    #         # 4ï¸âƒ£ Asystent (z kodem)
    #         memory.add_assistant(
    #             """Oto gotowy skrypt:
    #
    # ```python
    # import csv
    #
    # with open('dane.csv', 'r', encoding='utf-8') as f:
    #     reader = csv.reader(f)
    #     rows = list(reader)
    #
    # print(f'Liczba wierszy (w tym nagÅ‚Ã³wek): {len(rows)}')
    # print(f'Liczba wierszy danych: {len(rows)-1}')
    # ```"""
    #         )
    #         # 5ï¸âƒ£ UÅ¼ytkownik
    #         memory.add_user("DziaÅ‚a! A jak mogÄ™ zapisaÄ‡ wynik do pliku `wynik.txt`?")
    #         # 6ï¸âƒ£ Asystent
    #         memory.add_assistant(
    #             """Dodaj na koÅ„cu:
    #
    # ```python
    # with open('wynik.txt', 'w') as out:
    #     out.write(f'Liczba wierszy danych: {len(rows)-1}')
    # ```"""
    #         )
    #         # 7ï¸âƒ£ UÅ¼ytkownik (proÅ›ba o czas)
    #         memory.add_user("A teraz pokaÅ¼ mi aktualny czas, proszÄ™.")
    #         # 8ï¸âƒ£ Asystent (wywoÅ‚uje narzÄ™dzie `local_time`)
    #         #   (model sam wywoÅ‚a narzÄ™dzie â€“ my tylko symulujemy historiÄ™)
    #         memory.add_assistant(
    #             """WywoÅ‚ujÄ™ narzÄ™dzie `local_time`â€¦
    # ğŸ”” ProszÄ™ chwilÄ™, sprawdzam aktualny czasâ€¦"""
    #         )
    #         # 9ï¸âƒ£ Wynik narzÄ™dzia (symulowany)
    #         memory.add_tool_result(
    #             "local_time", {"epoch": 1717020000, "iso": "2024-06-01 12:00:00"}
    #         )
    #         # ğŸ”Ÿ KoÅ„cowa odpowiedÅº asystenta
    #         memory.add_assistant(
    #             "Aktualny czas to: **2024â€‘06â€‘01 12:00:00** (czas lokalny)."
    #         )

    # -------------------------------------------------
    # JeÅ›li historia jest dÅ‚uga â€“ od razu streszczamy
    # -------------------------------------------------
    if memory.approx_char_count() > 6000:
        memory.summarize_history(keep_last_n=8)

    # -------------------------------------------------
    # RozpoczÄ™cie interaktywnego czatu
    # -------------------------------------------------
    print("\nğŸ“š Historia rozmowy zostaÅ‚a wczytana! Wpisz `exit` aby zakoÅ„czyÄ‡.\n")

    while True:
        user_text = input("Ty: ").strip()
        if not user_text:
            continue
        if user_text.lower() in ("exit", "quit"):
            break

        memory.add_user(user_text)

        # Streszczamy, gdy historia roÅ›nie
        if memory.approx_char_count() > 6000:
            memory.summarize_history(keep_last_n=8)

        try:
            assistant_text = run_with_tools(memory, temperature=0.7)
        except Exception as e:
            assistant_text = f"âŒ BÅÄ„D: {e}"

        memory.add_assistant(assistant_text)
        print(f"\nAsystent: {assistant_text}\n")


if __name__ == "__main__":
    main()
